- config file path = /cluster/home/anghosh/DHProject/deep-mimic/data/conf/bob_env_multi_walkpunch.json
wandb: Currently logged in as: ankitaghosh0907 (dh-project). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in /cluster/home/anghosh/DHProject/deep-mimic/log/wandb/run-20230613_122441-4zf62xex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 2023-06-13-12-24-39-PylocoMultiClip-v0-['humanoid3d_walk_to_ready_final.txt', 'sie_humanoid3d_punch_forward02.txt']-100.0M_1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/dh-project/DH-Project
wandb: üöÄ View run at https://wandb.ai/dh-project/DH-Project/runs/4zf62xex
wandb: WARNING Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
Ignoring input line: position 0 0.90 0
(217, 35)
frames_shape (394, 44)
frames_time [0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333 0.00833333
 0.00833333 0.00833333 0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333   0.008333   0.008333
 0.008333   0.008333   0.008333   0.008333  ]
frames x and z positions [0.         0.01457    0.02965    0.04523    0.06097    0.07662
 0.09206    0.10846    0.12457    0.14027    0.15577    0.17109
 0.18674    0.20365    0.21935    0.234      0.24869    0.26249
 0.27618    0.28952    0.3026     0.31533    0.32766    0.34032
 0.35293    0.36534    0.37757    0.38949    0.40165    0.41387
 0.42521    0.43664    0.44853    0.46016    0.47158    0.48246
 0.49281    0.50345    0.51394    0.52453    0.53538    0.54665
 0.55731    0.56776    0.57848    0.5891     0.5996     0.60999
 0.62048    0.63138    0.64251    0.65381    0.66534    0.67708
 0.68867    0.70039    0.71226    0.72389    0.73538    0.74683
 0.75842    0.77156    0.78378    0.79706    0.81041    0.82382
 0.83723    0.8508     0.86461    0.87849    0.89211    0.90558
 0.91871    0.93139    0.94376    0.95569    0.9669     0.97736
 0.98743    0.99754    1.00779    1.01775    1.02752    1.0373
 1.0469     1.05639    1.066      1.07555    1.08476    1.09343
 1.10156    1.10954    1.11789    1.12644    1.13447    1.14242
 1.15047    1.15839    1.1658     1.17289    1.18026    1.18745
 1.19457    1.20172    1.20898    1.21628    1.22376    1.23131
 1.23893    1.24647    1.25397    1.26127    1.26824    1.27506
 1.28195    1.28958    1.29693    1.30445    1.3117     1.31868
 1.32492    1.33174    1.339      1.34609    1.35305    1.36004
 1.36581    1.37232    1.37912    1.38589    1.39277    1.3995
 1.40598    1.41223    1.41804    1.42348    1.42884    1.43408
 1.43922    1.44379    1.44739    1.45078    1.45451    1.45809
 1.46146    1.46453    1.46724    1.46958    1.47191    1.47389
 1.47557    1.47708    1.47841    1.47969    1.48059    1.48107
 1.48126    1.48145    1.48172    1.48195    1.48218    1.48252
 1.48288    1.48318    1.48326    1.48322    1.48311    1.4827
 1.48217    1.48156    1.48034    1.47897    1.47766    1.47615
 1.47479    1.47339    1.47176    1.46998    1.46823    1.46638
 1.46438    1.46246    1.46054    1.4588     1.45726    1.45561
 1.45404    1.45276    1.45177    1.45088    1.44999    1.4493
 1.44897    1.4485     1.44791    1.44751    1.4474     1.44752
 1.4477     1.44789    1.44803    1.44851    1.44924    1.44995
 1.4506     1.45125    1.45186    1.45254    1.45332    1.45404
 1.45463    1.45516    1.45588    1.45648    1.45727    1.45784
 1.45838    1.45894    1.47801117 1.48064578 1.48334936 1.48612549
 1.48898018 1.49190755 1.49491294 1.49799152 1.50112813 1.50429081
 1.50744774 1.5105726  1.51367913 1.51681194 1.51998734 1.52322881
 1.52662414 1.53022042 1.53400518 1.53797131 1.54212065 1.54644681
 1.55097279 1.55574638 1.56079531 1.56610108 1.57158162 1.57713137
 1.58265075 1.58809115 1.59347484 1.59884326 1.60418002 1.60946879
 1.61474084 1.62006608 1.62531161 1.63026734 1.63485838 1.63910362
 1.64302173 1.64667324 1.65012396 1.65341442 1.6565963  1.6597309
 1.66287191 1.66604928 1.66925613 1.67244695 1.67557278 1.67858856
 1.6814586  1.68413432 1.68659575 1.68885327 1.69093434 1.69287171
 1.69471274 1.69650463 1.69825911 1.699965   1.70160019 1.70314907
 1.70458966 1.7059086  1.70710029 1.70815969 1.70908126 1.70985808
 1.71048992 1.71098579 1.71135509 1.71161404 1.71177995 1.71186969
 1.711895   1.71186222 1.71177293 1.71164128 1.71147656 1.71128448
 1.71106271 1.71080022 1.71048354 1.71010147 1.70964083 1.70908706
 1.70842747 1.70764266 1.70670067 1.70557039 1.70425618 1.70279167
 1.70121526 1.69954743 1.69779903 1.69596767 1.6940462  1.69199115
 1.68976045 1.68732598 1.68467872 1.68182369 1.67878082 1.67557254
 1.67223731 1.66883032 1.66542392 1.66210312 1.65894229 1.65598651
 1.65326918 1.650794   1.64857059 1.64658284 1.64478109 1.64316098
 1.64176707 1.64064125 1.63976181 1.63911229 1.63865538 1.63830696
 1.63798547 1.63764084 1.63718442 1.63658123 1.6358815  1.63510309
 1.63421474 1.63325004 1.63231245 1.63150936 1.63089918 1.63047432
 1.63022062 1.63011782 1.63013763 1.63026977 1.63053004 1.63091552
 1.63139868 1.63195106 1.63254356 1.63314332 1.63372291 1.6342582
 1.63473622 1.63514798 1.63549588 1.63578319 1.63601593 1.63619774
 1.63633151 1.63641933 1.6364607  1.6364617  1.63642681 1.63636513
 1.63628714 1.63620379 1.63612452 1.63605736 1.63601816 1.63602267
 1.63606785 1.63616149 1.63631261 1.63651845 1.6367832  1.63710113
 1.63746581 1.63787279 1.63831066 1.63877025] [ 0.         -0.00124    -0.00233    -0.00331    -0.00421    -0.0053
 -0.00707    -0.00898    -0.01087    -0.01332    -0.0159     -0.01815
 -0.01999    -0.02265    -0.02386    -0.02494    -0.02602    -0.02746
 -0.02884    -0.03016    -0.03112    -0.03186    -0.03256    -0.03309
 -0.03374    -0.0347     -0.03543    -0.03585    -0.03607    -0.03615
 -0.03617    -0.03658    -0.03724    -0.03771    -0.03775    -0.03764
 -0.0376     -0.03775    -0.03815    -0.03853    -0.03881    -0.03928
 -0.03965    -0.03957    -0.03994    -0.04024    -0.04045    -0.04068
 -0.04097    -0.04111    -0.04114    -0.04102    -0.04071    -0.04033
 -0.03974    -0.03909    -0.03868    -0.03858    -0.03847    -0.03802
 -0.03729    -0.03618    -0.03597    -0.03479    -0.03364    -0.03249
 -0.03102    -0.02911    -0.0273     -0.02549    -0.02362    -0.02161
 -0.01943    -0.01749    -0.01612    -0.01495    -0.01383    -0.01289
 -0.01198    -0.01096    -0.01022    -0.00969    -0.00906    -0.00812
 -0.00698    -0.00603    -0.0051     -0.00424    -0.00362    -0.00326
 -0.00311    -0.00328    -0.00351    -0.00363    -0.00365    -0.00334
 -0.00276    -0.00252    -0.00249    -0.00242    -0.00259    -0.00345
 -0.00426    -0.00484    -0.00551    -0.00646    -0.00722    -0.00765
 -0.00803    -0.0088     -0.00961    -0.01016    -0.01055    -0.01149
 -0.01251    -0.01334    -0.01442    -0.01508    -0.01551    -0.0168
 -0.01764    -0.01861    -0.01959    -0.02068    -0.02209    -0.02368
 -0.02462    -0.02607    -0.0279     -0.02967    -0.0317     -0.03425
 -0.03677    -0.03884    -0.04076    -0.04289    -0.04524    -0.04782
 -0.05011    -0.05209    -0.05392    -0.0555     -0.05728    -0.05958
 -0.062      -0.06394    -0.06567    -0.06761    -0.0695     -0.07102
 -0.0723     -0.07361    -0.07515    -0.0764     -0.07754    -0.07856
 -0.07962    -0.08054    -0.08125    -0.08179    -0.08259    -0.0834
 -0.08424    -0.08476    -0.08562    -0.08656    -0.08755    -0.08872
 -0.08982    -0.09091    -0.09218    -0.09321    -0.09414    -0.0953
 -0.09618    -0.09708    -0.09834    -0.09967    -0.10072    -0.10162
 -0.10251    -0.10342    -0.10422    -0.10473    -0.10492    -0.10516
 -0.10533    -0.10561    -0.10579    -0.10593    -0.10597    -0.10607
 -0.10641    -0.10668    -0.1066     -0.10636    -0.10618    -0.10621
 -0.10632    -0.10637    -0.1064     -0.10671    -0.10696    -0.1071
 -0.10728    -0.10749    -0.10784    -0.10828    -0.10865    -0.10899
 -0.10951    -0.10985    -0.11005    -0.11054    -0.11081    -0.11123
 -0.11146    -0.11167    -0.1148168  -0.11545094 -0.11612205 -0.11682665
 -0.11755597 -0.11831978 -0.11912045 -0.11995153 -0.1208209  -0.12172235
 -0.12263458 -0.12353156 -0.12438544 -0.12517367 -0.12588118 -0.12649404
 -0.1269885  -0.12733768 -0.12753001 -0.1275734  -0.12750791 -0.12738873
 -0.12730573 -0.12735385 -0.12761232 -0.12812772 -0.12892108 -0.12999414
 -0.13133985 -0.1329228  -0.13471914 -0.13669664 -0.13882002 -0.14104593
 -0.14336654 -0.14583482 -0.14850115 -0.15131951 -0.15414587 -0.15682886
 -0.15924835 -0.16129726 -0.16292026 -0.16412755 -0.16496322 -0.1654591
 -0.165651   -0.16559471 -0.16534143 -0.16495612 -0.16450012 -0.16401719
 -0.16357009 -0.16321507 -0.1629868  -0.1628961  -0.16292856 -0.16308827
 -0.16337551 -0.16377248 -0.1642596  -0.16481106 -0.16539426 -0.16597183
 -0.16652023 -0.16702094 -0.16745249 -0.16779835 -0.1680461  -0.16818853
 -0.16822365 -0.16815942 -0.16800681 -0.16777492 -0.16747373 -0.16710926
 -0.16668713 -0.1662096  -0.16568151 -0.16510316 -0.16447645 -0.16379865
 -0.16306705 -0.1622739  -0.16140775 -0.16044276 -0.15935332 -0.15811906
 -0.15671834 -0.15512429 -0.15333074 -0.1513636  -0.14925057 -0.14702785
 -0.14473813 -0.14241719 -0.14007985 -0.13773948 -0.13541206 -0.133121
 -0.1308684  -0.12867981 -0.12658051 -0.12458702 -0.12271405 -0.1209639
 -0.11933796 -0.11783456 -0.1164439  -0.11515266 -0.11394273 -0.11279555
 -0.11170404 -0.1106738  -0.10971776 -0.10886911 -0.10817517 -0.10764151
 -0.10722041 -0.10685843 -0.10651793 -0.10615455 -0.10572649 -0.10520467
 -0.10457281 -0.10382489 -0.10294447 -0.10193379 -0.10083309 -0.09970668
 -0.09862888 -0.09774368 -0.09725611 -0.09724581 -0.09757171 -0.09803831
 -0.09853751 -0.09898516 -0.09927287 -0.09936563 -0.09935216 -0.09932451
 -0.09931321 -0.09933279 -0.09940894 -0.09956984 -0.09982184 -0.10014872
 -0.10053493 -0.10096444 -0.10142386 -0.1018987  -0.10237211 -0.10283255
 -0.10327063 -0.10368708 -0.104086   -0.10446766 -0.10482749 -0.10514926
 -0.10541963 -0.1056292  -0.1057728  -0.10585852 -0.10589249 -0.10587985
 -0.1058371  -0.10577033 -0.10568751 -0.10559907 -0.10551455 -0.10543667
 -0.10536218 -0.10528759 -0.10521027 -0.10512929]
Ignoring input line: position 0 0.90 0
Logging to /cluster/home/anghosh/DHProject/deep-mimic/log/2023-06-13-12-24-39-PylocoMultiClip-v0-['humanoid3d_walk_to_ready_final.txt', 'sie_humanoid3d_punch_forward02.txt']-100.0M_1
/cluster/home/anghosh/venv/lib64/python3.9/site-packages/stable_baselines3/common/callbacks.py:345: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x2ac6831f8fa0> != <stable_baselines3.common.vec_env.vec_video_recorder.VecVideoRecorder object at 0x2ac68341d220>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
--------------------------------------
| err_terms/              |          |
|    com_err              | 0.0186   |
|    end_effectors_err    | 0.00636  |
|    height_err           | 0.0114   |
|    joints_err           | 0.0435   |
|    joints_vel_err       | 119      |
|    root_ori_err         | 0.00128  |
| reward_terms/           |          |
|    com_reward           | 0.0996   |
|    end_effectors_reward | 0.0498   |
|    height_reward        | 0.0993   |
|    joints_reward        | 0.46     |
|    joints_vel_reward    | 6.14e-07 |
|    root_ori_reward      | 0.0598   |
|    smoothness1_reward   | 0        |
|    smoothness2_reward   | 0        |
|    smoothness_reward    | 0        |
| rollout/                |          |
|    ep_len_mean          | 37.6     |
|    ep_rew_mean          | 6.59     |
| time/                   |          |
|    collect_time         | 79.5     |
|    fps                  | 1030     |
|    iterations           | 1        |
|    time_elapsed         | 79       |
|    total_timesteps      | 81920    |
--------------------------------------
-----------------------------------------
| err_terms/               |            |
|    com_err               | 0.291      |
|    end_effectors_err     | 1.73       |
|    height_err            | 0.00633    |
|    joints_err            | 8.17       |
|    joints_vel_err        | 147        |
|    root_ori_err          | 0.299      |
| reward_terms/            |            |
|    com_reward            | 0.0522     |
|    end_effectors_reward  | 0.0218     |
|    height_reward         | 0.0589     |
|    joints_reward         | 0.0082     |
|    joints_vel_reward     | 1.39e-05   |
|    root_ori_reward       | 0.00143    |
|    smoothness1_reward    | 0          |
|    smoothness2_reward    | 0          |
|    smoothness_reward     | 0          |
| rollout/                 |            |
|    ep_len_mean           | 30.4       |
|    ep_rew_mean           | 5.81       |
| time/                    |            |
|    collect_time          | 74.3       |
|    evaluate_actions_time | 0.00115    |
|    fps                   | 943        |
|    iterations            | 2          |
|    time_elapsed          | 173        |
|    total_timesteps       | 163840     |
|    train_time            | 19.9       |
| train/                   |            |
|    approx_kl             | 0.04561084 |
|    clip_fraction         | 0.36       |
|    clip_range            | 0.2        |
|    entropy_loss          | -5.21      |
|    explained_variance    | -0.107     |
|    learning_rate_log_std | 0.0003     |
|    learning_rate_policy  | 5e-05      |
|    learning_rate_value   | 0.01       |
|    loss                  | -0.0509    |
|    n_updates             | 10         |
|    policy_gradient_loss  | -0.0556    |
|    std                   | 0.272      |
|    value_loss            | 0.58       |
-----------------------------------------
-----------------------------------------
| err_terms/               |            |
|    com_err               | 0.3        |
|    end_effectors_err     | 1.69       |
|    height_err            | 0.0117     |
|    joints_err            | 8.95       |
|    joints_vel_err        | 282        |
|    root_ori_err          | 0.209      |
| reward_terms/            |            |
|    com_reward            | 0.0472     |
|    end_effectors_reward  | 0.0203     |
|    height_reward         | 0.0601     |
|    joints_reward         | 0.00976    |
|    joints_vel_reward     | 2.24e-06   |
|    root_ori_reward       | 0.00468    |
|    smoothness1_reward    | 0          |
|    smoothness2_reward    | 0          |
|    smoothness_reward     | 0          |
| rollout/                 |            |
|    ep_len_mean           | 33.3       |
|    ep_rew_mean           | 6.14       |
| time/                    |            |
|    collect_time          | 74.1       |
|    evaluate_actions_time | 0.00115    |
|    fps                   | 918        |
|    iterations            | 3          |
|    time_elapsed          | 267        |
|    total_timesteps       | 245760     |
|    train_time            | 19.8       |
| train/                   |            |
|    approx_kl             | 0.04423812 |
|    clip_fraction         | 0.375      |
|    clip_range            | 0.2        |
|    entropy_loss          | -5.17      |
|    explained_variance    | 0.82       |
|    learning_rate_log_std | 0.0003     |
|    learning_rate_policy  | 5e-05      |
|    learning_rate_value   | 0.01       |
|    loss                  | -0.0937    |
|    n_updates             | 20         |
|    policy_gradient_loss  | -0.0713    |
|    std                   | 0.272      |
|    value_loss            | 0.071      |
-----------------------------------------
------------------------------------------
| err_terms/               |             |
|    com_err               | 0.13        |
|    end_effectors_err     | 1.17        |
|    height_err            | 0.067       |
|    joints_err            | 8.99        |
|    joints_vel_err        | 169         |
|    root_ori_err          | 0.15        |
| reward_terms/            |             |
|    com_reward            | 0.0793      |
|    end_effectors_reward  | 0.0254      |
|    height_reward         | 0.0776      |
|    joints_reward         | 0.00825     |
|    joints_vel_reward     | 2.87e-05    |
|    root_ori_reward       | 0.00441     |
|    smoothness1_reward    | 0           |
|    smoothness2_reward    | 0           |
|    smoothness_reward     | 0           |
| rollout/                 |             |
|    ep_len_mean           | 35.8        |
|    ep_rew_mean           | 6.32        |
| time/                    |             |
|    collect_time          | 75.9        |
|    evaluate_actions_time | 0.00111     |
|    fps                   | 903         |
|    iterations            | 4           |
|    time_elapsed          | 362         |
|    total_timesteps       | 327680      |
|    train_time            | 19          |
| train/                   |             |
|    approx_kl             | 0.048561856 |
|    clip_fraction         | 0.404       |
|    clip_range            | 0.2         |
|    entropy_loss          | -5.11       |
|    explained_variance    | 0.914       |
|    learning_rate_log_std | 0.0003      |
|    learning_rate_policy  | 5e-05       |
|    learning_rate_value   | 0.01        |
|    loss                  | -0.0848     |
|    n_updates             | 30          |
|    policy_gradient_loss  | -0.0736     |
|    std                   | 0.272       |
|    value_loss            | 0.0597      |
------------------------------------------
-----------------------------------------
| err_terms/               |            |
|    com_err               | 0.182      |
|    end_effectors_err     | 1.09       |
|    height_err            | 0.0295     |
|    joints_err            | 7.93       |
|    joints_vel_err        | 170        |
|    root_ori_err          | 0.155      |
| reward_terms/            |            |
|    com_reward            | 0.0658     |
|    end_effectors_reward  | 0.0263     |
|    height_reward         | 0.0926     |
|    joints_reward         | 0.0106     |
|    joints_vel_reward     | 9.13e-06   |
|    root_ori_reward       | 0.000892   |
|    smoothness1_reward    | 0          |
|    smoothness2_reward    | 0          |
|    smoothness_reward     | 0          |
| rollout/                 |            |
|    ep_len_mean           | 37.9       |
|    ep_rew_mean           | 6.71       |
| time/                    |            |
|    collect_time          | 79.4       |
|    evaluate_actions_time | 0.00113    |
|    fps                   | 888        |
|    iterations            | 5          |
|    time_elapsed          | 461        |
|    total_timesteps       | 409600     |
|    train_time            | 19.2       |
| train/                   |            |
|    approx_kl             | 0.05636819 |
|    clip_fraction         | 0.428      |
|    clip_range            | 0.2        |
|    entropy_loss          | -5.07      |
|    explained_variance    | 0.93       |
|    learning_rate_log_std | 0.0003     |
|    learning_rate_policy  | 5e-05      |
|    learning_rate_value   | 0.01       |
|    loss                  | -0.0691    |
|    n_updates             | 40         |
|    policy_gradient_loss  | -0.0724    |
|    std                   | 0.271      |
|    value_loss            | 0.0559     |
-----------------------------------------
------------------------------------------
| err_terms/               |             |
|    com_err               | 0.0603      |
|    end_effectors_err     | 0.532       |
|    height_err            | 0.0455      |
|    joints_err            | 4.94        |
|    joints_vel_err        | 232         |
|    root_ori_err          | 0.00613     |
| reward_terms/            |             |
|    com_reward            | 0.095       |
|    end_effectors_reward  | 0.0364      |
|    height_reward         | 0.0892      |
|    joints_reward         | 0.0244      |
|    joints_vel_reward     | 2.6e-06     |
|    root_ori_reward       | 0.0183      |
|    smoothness1_reward    | 0           |
|    smoothness2_reward    | 0           |
|    smoothness_reward     | 0           |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | 7.81        |
| time/                    |             |
|    collect_time          | 79.3        |
|    evaluate_actions_time | 0.00112     |
|    fps                   | 878         |
|    iterations            | 6           |
|    time_elapsed          | 559         |
|    total_timesteps       | 491520      |
|    train_time            | 19.1        |
| train/                   |             |
|    approx_kl             | 0.056429673 |
|    clip_fraction         | 0.449       |
|    clip_range            | 0.2         |
|    entropy_loss          | -5.01       |
|    explained_variance    | 0.952       |
|    learning_rate_log_std | 0.0003      |
|    learning_rate_policy  | 5e-05       |
|    learning_rate_value   | 0.01        |
|    loss                  | -0.0894     |
|    n_updates             | 50          |
|    policy_gradient_loss  | -0.0724     |
|    std                   | 0.271       |
|    value_loss            | 0.049       |
------------------------------------------
------------------------------------------
| err_terms/               |             |
|    com_err               | 0.0139      |
|    end_effectors_err     | 0.0103      |
|    height_err            | 0.0108      |
|    joints_err            | 0.0437      |
|    joints_vel_err        | 107         |
|    root_ori_err          | 0.000379    |
| reward_terms/            |             |
|    com_reward            | 0.0998      |
|    end_effectors_reward  | 0.0497      |
|    height_reward         | 0.0994      |
|    joints_reward         | 0.46        |
|    joints_vel_reward     | 1.99e-06    |
|    root_ori_reward       | 0.0859      |
|    smoothness1_reward    | 0           |
|    smoothness2_reward    | 0           |
|    smoothness_reward     | 0           |
| rollout/                 |             |
|    ep_len_mean           | 36.7        |
|    ep_rew_mean           | 6.63        |
| time/                    |             |
|    collect_time          | 79          |
|    evaluate_actions_time | 0.00113     |
|    fps                   | 871         |
|    iterations            | 7           |
|    time_elapsed          | 658         |
|    total_timesteps       | 573440      |
|    train_time            | 19.4        |
| train/                   |             |
|    approx_kl             | 0.060334682 |
|    clip_fraction         | 0.461       |
|    clip_range            | 0.2         |
|    entropy_loss          | -4.98       |
|    explained_variance    | 0.96        |
|    learning_rate_log_std | 0.0003      |
|    learning_rate_policy  | 5e-05       |
|    learning_rate_value   | 0.01        |
|    loss                  | -0.079      |
|    n_updates             | 60          |
|    policy_gradient_loss  | -0.0711     |
|    std                   | 0.271       |
|    value_loss            | 0.0467      |
------------------------------------------
-----------------------------------------
| err_terms/               |            |
|    com_err               | 0.228      |
|    end_effectors_err     | 1.34       |
|    height_err            | 0.00967    |
|    joints_err            | 8.17       |
|    joints_vel_err        | 140        |
|    root_ori_err          | 0.208      |
| reward_terms/            |            |
|    com_reward            | 0.0614     |
|    end_effectors_reward  | 0.0241     |
|    height_reward         | 0.0658     |
|    joints_reward         | 0.00717    |
|    joints_vel_reward     | 1.88e-05   |
|    root_ori_reward       | 0.00545    |
|    smoothness1_reward    | 0          |
|    smoothness2_reward    | 0          |
|    smoothness_reward     | 0          |
| rollout/                 |            |
|    ep_len_mean           | 30.6       |
|    ep_rew_mean           | 5.92       |
| time/                    |            |
|    collect_time          | 78.4       |
|    evaluate_actions_time | 0.00114    |
|    fps                   | 866        |
|    iterations            | 8          |
|    time_elapsed          | 756        |
|    total_timesteps       | 655360     |
|    train_time            | 19.7       |
| train/                   |            |
|    approx_kl             | 0.06565203 |
|    clip_fraction         | 0.478      |
|    clip_range            | 0.2        |
|    entropy_loss          | -4.94      |
|    explained_variance    | 0.966      |
|    learning_rate_log_std | 0.0003     |
|    learning_rate_policy  | 5e-05      |
|    learning_rate_value   | 0.01       |
|    loss                  | -0.0982    |
|    n_updates             | 70         |
|    policy_gradient_loss  | -0.0713    |
|    std                   | 0.271      |
|    value_loss            | 0.0435     |
-----------------------------------------
------------------------------------------
| err_terms/               |             |
|    com_err               | 0.0865      |
|    end_effectors_err     | 0.801       |
|    height_err            | 0.0454      |
|    joints_err            | 7.88        |
|    joints_vel_err        | 181         |
|    root_ori_err          | 0.056       |
| reward_terms/            |             |
|    com_reward            | 0.09        |
|    end_effectors_reward  | 0.031       |
|    height_reward         | 0.0897      |
|    joints_reward         | 0.0135      |
|    joints_vel_reward     | 2.38e-05    |
|    root_ori_reward       | 0.00401     |
|    smoothness1_reward    | 0           |
|    smoothness2_reward    | 0           |
|    smoothness_reward     | 0           |
| rollout/                 |             |
|    ep_len_mean           | 38.5        |
|    ep_rew_mean           | 7.11        |
| time/                    |             |
|    collect_time          | 78.2        |
|    evaluate_actions_time | 0.00111     |
|    fps                   | 864         |
|    iterations            | 9           |
|    time_elapsed          | 853         |
|    total_timesteps       | 737280      |
|    train_time            | 18.9        |
| train/                   |             |
|    approx_kl             | 0.068687975 |
|    clip_fraction         | 0.487       |
|    clip_range            | 0.2         |
|    entropy_loss          | -4.9        |
|    explained_variance    | 0.966       |
|    learning_rate_log_std | 0.0003      |
|    learning_rate_policy  | 5e-05       |
|    learning_rate_value   | 0.01        |
|    loss                  | -0.0122     |
|    n_updates             | 80          |
|    policy_gradient_loss  | -0.0679     |
|    std                   | 0.27        |
|    value_loss            | 0.0468      |
------------------------------------------
-----------------------------------------
| err_terms/               |            |
|    com_err               | 0.269      |
|    end_effectors_err     | 1.42       |
|    height_err            | 0.01       |
|    joints_err            | 7.82       |
|    joints_vel_err        | 409        |
|    root_ori_err          | 0.217      |
| reward_terms/            |            |
|    com_reward            | 0.0572     |
|    end_effectors_reward  | 0.0247     |
|    height_reward         | 0.064      |
|    joints_reward         | 0.0109     |
|    joints_vel_reward     | 7.83e-06   |
|    root_ori_reward       | 0.00234    |
|    smoothness1_reward    | 0          |
|    smoothness2_reward    | 0          |
|    smoothness_reward     | 0          |
| rollout/                 |            |
|    ep_len_mean           | 37.1       |
|    ep_rew_mean           | 6.64       |
| time/                    |            |
|    collect_time          | 75.8       |
|    evaluate_actions_time | 0.00113    |
|    fps                   | 863        |
|    iterations            | 10         |
|    time_elapsed          | 948        |
|    total_timesteps       | 819200     |
|    train_time            | 19.6       |
| train/                   |            |
|    approx_kl             | 0.07224931 |
|    clip_fraction         | 0.5        |
|    clip_range            | 0.2        |
|    entropy_loss          | -4.85      |
|    explained_variance    | 0.971      |
|    learning_rate_log_std | 0.0003     |
|    learning_rate_policy  | 5e-05      |
|    learning_rate_value   | 0.01       |
|    loss                  | -0.0295    |
|    n_updates             | 90         |
|    policy_gradient_loss  | -0.0692    |
|    std                   | 0.27       |
|    value_loss            | 0.043      |
-----------------------------------------
